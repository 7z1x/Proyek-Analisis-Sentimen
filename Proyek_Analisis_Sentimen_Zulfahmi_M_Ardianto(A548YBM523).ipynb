{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhhuvTRr8kV_",
        "outputId": "57d54ecd-2345-4329-c58c-9aaf3c1c7d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-play-scraper in /usr/local/lib/python3.11/dist-packages (1.2.7)\n",
            "Requirement already satisfied: sastrawi in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-play-scraper\n",
        "!pip install sastrawi\n",
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.3 gensim==4.3.2\n",
        "!pip install --upgrade scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc6mNMDKEc2D",
        "outputId": "64842583-30df-47ff-9138-de02bb68b641"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.11/dist-packages (1.24.3)\n",
            "Requirement already satisfied: gensim==4.3.2 in /usr/local/lib/python3.11/dist-packages (4.3.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.2) (1.10.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.2) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim==4.3.2) (1.17.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.10.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from google_play_scraper import app, reviews, Sort, reviews_all\n",
        "import emoji\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "import requests\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9agJqYv8pk7",
        "outputId": "1a2eed50-c618-47a1-baf9-b77c82828e50"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scrapreview = reviews_all(\n",
        "    'com.gojek.gopay',\n",
        "    lang='id',\n",
        "    country='id',\n",
        "    sort=Sort.MOST_RELEVANT,\n",
        ")\n",
        "\n",
        "scrapreview = scrapreview[:5000]"
      ],
      "metadata": {
        "id": "tJ0HjuBN8q-_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gopay_reviews.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Review'])\n",
        "    for review in scrapreview:\n",
        "        writer.writerow([review['content']])"
      ],
      "metadata": {
        "id": "NHotnW6l9KXT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Misalkan scrapreview sudah diubah ke DataFrame\n",
        "app_reviews_df = pd.DataFrame(scrapreview)\n",
        "# Fungsi untuk memberi label berdasarkan skor\n",
        "def label_sentiment(score):\n",
        "    if score >= 4:\n",
        "        return 'positif'\n",
        "    elif score == 3:\n",
        "        return 'netral'\n",
        "    else:\n",
        "        return 'negatif'\n",
        "\n",
        "# Tambahkan kolom 'sentiment' ke DataFrame\n",
        "app_reviews_df['sentiment'] = app_reviews_df['score'].apply(label_sentiment)\n",
        "\n",
        "# Simpan ke CSV untuk memastikan hasilnya\n",
        "app_reviews_df.to_csv('ulasan_dengan_label.csv', index=False)\n",
        "\n",
        "# Cek jumlah data dan distribusi sentimen\n",
        "print(f\"Jumlah ulasan: {len(app_reviews_df)}\")\n",
        "print(app_reviews_df['sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjF5FfPI9Kg7",
        "outputId": "fab26020-1ec4-41a4-f266-1c105833d6bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah ulasan: 5000\n",
            "sentiment\n",
            "negatif    3168\n",
            "positif    1459\n",
            "netral      373\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Misalkan data sudah di-load dari CSV hasil langkah sebelumnya\n",
        "app_reviews_df = pd.read_csv('ulasan_dengan_label.csv')\n",
        "\n",
        "def remove_emoji(text):\n",
        "    return emoji.replace_emoji(text, replace='')\n",
        "\n",
        "def cleaningText(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # menghapus mention\n",
        "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # menghapus hashtag\n",
        "    text = re.sub(r'RT[\\s]', '', text) # menghapus RT\n",
        "    text = re.sub(r\"http\\S+\", '', text) # menghapus link\n",
        "    text = re.sub(r'[0-9]+', '', text) # menghapus angka\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) # menghapus karakter selain huruf dan angka\n",
        "    text = remove_emoji(text)  # Hapus emoji\n",
        "\n",
        "\n",
        "    text = text.replace('\\n', ' ') # mengganti baris baru dengan spasi\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # menghapus semua tanda baca\n",
        "    text = text.strip(' ') # menghapus karakter spasi dari kiri dan kanan teks\n",
        "    return text\n",
        "\n",
        "def casefoldingText(text): # Mengubah semua karakter dalam teks menjadi huruf kecil\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def tokenizingText(text): # Memecah atau membagi string, teks menjadi daftar token\n",
        "    text = word_tokenize(text)\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(word_list):\n",
        "    stopwords_indonesia = stopwords.words('indonesian')\n",
        "    no_words = [w for w in word_list if w.lower() not in stopwords_indonesia]\n",
        "    return no_words\n",
        "\n",
        "def toSentence(list_words): # Mengubah daftar kata menjadi kalimat\n",
        "    sentence = ' '.join(word for word in list_words)\n",
        "    return sentence\n",
        "\n",
        "def load_slangwords():\n",
        "    slangwords = {}\n",
        "    url = 'https://raw.githubusercontent.com/louisowen6/NLP_bahasa_resources/master/combined_slang_words.txt'\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Memastikan permintaan berhasil\n",
        "        # File berformat seperti dictionary Python, jadi kita evaluasi isinya\n",
        "        slangwords = eval(response.text)  # Konversi string ke dictionary\n",
        "        return slangwords\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Gagal mengambil slangword: {e}\")\n",
        "        return {}\n",
        "\n",
        "slangwords = load_slangwords()\n",
        "\n",
        "def fix_slangwords(text):\n",
        "    words = text.split()\n",
        "    fixed_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if word.lower() in slangwords:\n",
        "            fixed_words.append(slangwords[word.lower()])\n",
        "        else:\n",
        "            fixed_words.append(word)\n",
        "\n",
        "    fixed_text = ' '.join(fixed_words)\n",
        "    return fixed_text\n",
        "\n",
        "def preprocess(text):\n",
        "    text = cleaningText(text)\n",
        "    text = casefoldingText(text)\n",
        "    tokens = tokenizingText(text)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    fixed_text = fix_slangwords(' '.join(tokens))\n",
        "    return fixed_text\n",
        "\n",
        "# Terapkan preprocessing\n",
        "app_reviews_df['clean_text'] = app_reviews_df['content'].apply(preprocess)\n",
        "\n",
        "# Hapus baris dengan teks kosong\n",
        "app_reviews_df = app_reviews_df[app_reviews_df['clean_text'] != '']\n",
        "\n",
        "app_reviews_df = app_reviews_df.dropna()\n",
        "\n",
        "# Hapus duplikat\n",
        "app_reviews_df = app_reviews_df.drop_duplicates(subset=['clean_text'])\n",
        "\n",
        "# Simpan hasil\n",
        "app_reviews_df.to_csv('ulasan_clean.csv', index=False)\n",
        "\n",
        "# Cek beberapa baris\n",
        "print(app_reviews_df[['clean_text', 'sentiment']].head())\n",
        "print(f\"Jumlah data setelah preprocessing: {len(app_reviews_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn-4ogZ89NEC",
        "outputId": "6027f18f-70e4-45c2-e1ba-9fd9b0227a98"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          clean_text sentiment\n",
            "0  saldo kepotong top up game oke gapapa hitam be...   negatif\n",
            "2  kenapa gak masuk pin digit beda hp hp yang ter...   negatif\n",
            "3  kecewa sudah top up gak masuk masuk nunggu har...   negatif\n",
            "4  gopay mengecewakansaya driver gojek pagi siang...   negatif\n",
            "5  suka gopay murah saldo aman bikin kesel proses...   negatif\n",
            "Jumlah data setelah preprocessing: 3472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app_reviews_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NDYeyvF_ZSn",
        "outputId": "e4bcc028-112b-4510-e1b0-3448aed87fc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3472 entries, 0 to 4999\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   reviewId              3472 non-null   object\n",
            " 1   userName              3472 non-null   object\n",
            " 2   userImage             3472 non-null   object\n",
            " 3   content               3472 non-null   object\n",
            " 4   score                 3472 non-null   int64 \n",
            " 5   thumbsUpCount         3472 non-null   int64 \n",
            " 6   reviewCreatedVersion  3472 non-null   object\n",
            " 7   at                    3472 non-null   object\n",
            " 8   replyContent          3472 non-null   object\n",
            " 9   repliedAt             3472 non-null   object\n",
            " 10  appVersion            3472 non-null   object\n",
            " 11  sentiment             3472 non-null   object\n",
            " 12  clean_text            3472 non-null   object\n",
            "dtypes: int64(2), object(11)\n",
            "memory usage: 379.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df = pd.read_csv('ulasan_clean.csv')"
      ],
      "metadata": {
        "id": "JXxA2yKxAVw4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# svm tf idf"
      ],
      "metadata": {
        "id": "M5N0aXOyCaQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load data yang sudah dibersihkan\n",
        "clean_df = pd.read_csv('ulasan_clean.csv')\n",
        "\n",
        "# Mapping label ke angka\n",
        "label_map = {'negatif': 0, 'netral': 1, 'positif': 2}\n",
        "clean_df['label'] = clean_df['sentiment'].map(label_map)\n",
        "\n",
        "# Ekstraksi fitur TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=3000)  # ambil fitur top 5000\n",
        "X = tfidf.fit_transform(clean_df['clean_text']).toarray()\n",
        "y = clean_df['label']\n",
        "\n",
        "# Split data 80% train / 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Training SVM\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred_train_svm = svm_model.predict(X_train)\n",
        "y_pred_test_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluasi akurasi\n",
        "accuracy_train_svm = accuracy_score(y_train, y_pred_train_svm)\n",
        "accuracy_test_svm = accuracy_score(y_test, y_pred_test_svm)\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(\"SVM - Accuracy Train:\", accuracy_train_svm)\n",
        "print(\"SVM - Accuracy Test:\", accuracy_test_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC1i-vr7Ae73",
        "outputId": "f66bca18-eb88-4c47-ab17-281ff2aec59d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM - Accuracy Train: 0.8800864241987757\n",
            "SVM - Accuracy Test: 0.8762589928057554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Menggunakan model untuk prediksi\n",
        "y_pred_test_svm = svm_model.predict(X_test)  # Prediksi untuk data uji\n",
        "\n",
        "# Menampilkan hasil prediksi secara acak\n",
        "random_indices = random.sample(range(len(X_test)), 10)  # Pilih 10 indeks acak\n",
        "\n",
        "print(\"Prediksi Sentimen untuk Data Uji (Acak):\")\n",
        "for i in random_indices:\n",
        "    print(f\"Text: {clean_df['clean_text'].iloc[i]}, Prediksi: {y_pred_test_svm[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dueOAHFhORJG",
        "outputId": "1074306f-0c3c-4218-9af0-1c7cbb219c89"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediksi Sentimen untuk Data Uji (Acak):\n",
            "Text: gopay ga nyediain namanya gopaypargopay pelajar ga ktp saja gunain namanya transfer butuh transfer semacamnya gopay gopay par kalau batasan lulus sekolahsudah memiliki ktp, Prediksi: 0\n",
            "Text: ini iya saya top up itemku sudah benar tuh sudah terbaru aplikasinya saya bayar web habis web gak gopay nya saya manual hasilnya tidak tuh tombol transaksi ya sudah saya coba tetep gak ya sudah kayaknya gabisa deh emang bapuk ini aplikasi, Prediksi: 0\n",
            "Text: murah harga pulsapaket promo nya murah rp selebihnya saja murah iya murah harga aslinyapromo murahnya sengaja download buktikan dimana letak murahnya gak marketing comedy, Prediksi: 0\n",
            "Text: bug voucher gopay games aktif cashback cashbacknya masuk memenuhi sk yang berlaku voucher hilang voucher diluar gopay games, Prediksi: 0\n",
            "Text: top up flass bca saldo ga masuk saldo sdh dipotong update saldo ga lapor bank bank disuruh lapor gopay nyaandingnya uninstall aplikasi sajaanggap saja duit ilangsangat recomended aplikasinyabahkan sampai skr endingnya isi flazz bca dihapus gopay saldo ga baliksdh berlaluapk yang recomended sekaliwajar saja go partner sdh bangkrut, Prediksi: 0\n",
            "Text: kenapa top up gopay ga masuk kadang masuknya terlambat jm masuk apalah kecewa banget skarang juga top up saldonya belum masuk skali, Prediksi: 0\n",
            "Text: aplikasi panteqpake voucher cashback ga kembaliin duit nya pdhal pas transaksi tertulis voucher berhasil gunakandi laporin cs tutup aplikasi panteq emg makan tuh duit haram, Prediksi: 0\n",
            "Text: mengirim keluhan email kali muncul terdeteksi aktivitas wajarini gopay tolong fix secepat mungkinoh iya memiliki dana cukupbahkan, Prediksi: 0\n",
            "Text: deh ga pas berlaku pembayaran habis muncul tanda bayar nya emang deh ngeselin menit aplikasi v, Prediksi: 0\n",
            "Text: mengecewakan gopaysaya menunggu hariterkendala akibat transferan saldo masuk teman keteledoran gopaydikarenakan memasukan nomer penerima buktinyatpi digopay mendetect nomer terdaftar didalam gopay apk pundan uangsaldo reffund sekalisaya kecewa gopay rating bintang kasih rating, Prediksi: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# rf word2vec"
      ],
      "metadata": {
        "id": "cni2J1LaCb_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Load data bersih\n",
        "data = pd.read_csv('ulasan_clean.csv')\n",
        "label_map = {'negatif': 0, 'netral': 1, 'positif': 2}\n",
        "data['label'] = data['sentiment'].map(label_map)\n",
        "\n",
        "# Tokenizing untuk Word2Vec\n",
        "data['tokens'] = data['clean_text'].apply(nltk.word_tokenize)\n",
        "\n",
        "# Train Word2Vec model\n",
        "w2v_model = Word2Vec(sentences=data['tokens'], vector_size=100, window=5, min_count=1, sg=1)\n",
        "\n",
        "# Fungsi untuk merata-rata embedding setiap kalimat\n",
        "def vector_average(tokens):\n",
        "    vectors = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(w2v_model.vector_size)\n",
        "\n",
        "# Konversi semua text jadi vektor\n",
        "X_vectors = np.array([vector_average(tokens) for tokens in data['tokens']])\n",
        "y = data['label']\n",
        "\n",
        "# Split data\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(\n",
        "    X_vectors, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Training Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_w2v, y_train_w2v)\n",
        "\n",
        "y_pred_train_rf = rf_model.predict(X_train_w2v)\n",
        "y_pred_test_rf = rf_model.predict(X_test_w2v)\n",
        "\n",
        "print(\"Random Forest - accuracy_train:\", accuracy_score(y_pred_train_rf, y_train_w2v))\n",
        "print(\"Random Forest - accuracy_test :\", accuracy_score(y_pred_test_rf, y_test_w2v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzeB5KyKB3xX",
        "outputId": "4d6d90fc-a6d5-441e-a765-e07e1f87d3ca"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - accuracy_train: 1.0\n",
            "Random Forest - accuracy_test : 0.8705035971223022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_df['sentiment'].value_counts())\n",
        "print(f\"Training data: {len(X_train_w2v)}\")\n",
        "print(f\"Testing data: {len(X_test_w2v)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSTVa70dJJLU",
        "outputId": "f7778183-4134-49ca-b091-fd962947c8d8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "negatif    3043\n",
            "netral      357\n",
            "positif      72\n",
            "Name: count, dtype: int64\n",
            "Training data: 2777\n",
            "Testing data: 695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train_w2v, y_pred_train_rf)\n",
        "\n",
        "print(f\"Data training balanced: {Counter(y_train_bal)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrLGQhGMJbDE",
        "outputId": "a70b9513-8ca4-4c72-b1d9-102f67034176"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data training balanced: Counter({0: 2434, 1: 2434, 2: 2434})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Melatih model Random Forest dengan data yang seimbang\n",
        "rf_model_bal = RandomForestClassifier(random_state=42)\n",
        "rf_model_bal.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "# Prediksi pada data uji\n",
        "y_pred_bal = rf_model_bal.predict(X_test_w2v)\n",
        "\n",
        "# Evaluasi Model\n",
        "print(\"Random Forest (Data Seimbang) - Classification Report:\")\n",
        "print(classification_report(y_pred_test_rf, y_pred_bal))\n",
        "print(\"Akurasi (Test Data):\", accuracy_score(y_pred_test_rf, y_pred_bal))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iw14vImJ9Tp",
        "outputId": "ccd7bd3e-44a5-4b39-a2a1-cafa1453694e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest (Data Seimbang) - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97       689\n",
            "           1       0.08      0.60      0.14         5\n",
            "           2       0.09      1.00      0.17         1\n",
            "\n",
            "    accuracy                           0.93       695\n",
            "   macro avg       0.39      0.85      0.43       695\n",
            "weighted avg       0.99      0.93      0.96       695\n",
            "\n",
            "Akurasi (Test Data): 0.9338129496402877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan model untuk prediksi\n",
        "y_pred_bal = rf_model_bal.predict(X_test_w2v)  # Prediksi untuk data uji\n",
        "\n",
        "# Menampilkan hasil prediksi secara acak\n",
        "random_indices = random.sample(range(len(X_test_w2v)), 10)  # Pilih 10 indeks acak\n",
        "\n",
        "print(\"Prediksi Sentimen untuk Data Uji (Acak):\")\n",
        "for i in random_indices:\n",
        "    print(f\"Text: {clean_df['clean_text'].iloc[i]}, Prediksi: {y_pred_bal[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAeqCdHgPAuM",
        "outputId": "c9420c8e-61cb-4257-8137-0efacccb9a75"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediksi Sentimen untuk Data Uji (Acak):\n",
            "Text: saldo ga diakses upgrade gopay plus cek gopay tabungan rupiah tulisannya saldo transfer gopay tabungan maksudnya maksa nabung situ diakses tunggu minggu diakses, Prediksi: 0\n",
            "Text: gopay aneh war diskon sudah dapat giliran bayar kendala sudah coba tetep gabisa hadehh ngadain event yang benar sudah gitu cepat habis gilir dapat eh ga bayar aneh mendeteksi aktivitas gak wajar aneh gak wajar coba dapat diskon nya apk nya bilang aktivitas gak wajar kalau gak iklas memberikan mah gak ngadain event kocak dehh dasar, Prediksi: 0\n",
            "Text: top up gopay nominal masukÂ² ajukan bantuan respon informasi kendala sistem sistem libur menu bantuan seharus nya beranda biar pengguna tahu gopay libur apalah informasi taruh menu bantuan tolong dibenahi sistem nya kayak gini tiwas top up gopay ajar, Prediksi: 0\n",
            "Text: gopay transaksi limit an juta perbulan nya tolak mengaktifkan gopay pinjam alasan nya karena foto ktp huruf hilang bukti transaksi limit segitu gopay adil, Prediksi: 0\n",
            "Text: gopay ga nyediain namanya gopaypargopay pelajar ga ktp saja gunain namanya transfer butuh transfer semacamnya gopay gopay par kalau batasan lulus sekolahsudah memiliki ktp, Prediksi: 0\n",
            "Text: aneh banget promo sesuai ketentuan beli indomaret struk ditransaksi kalau beli indomaret promo payah promo scam, Prediksi: 0\n",
            "Text: trouble gmnbeli paketan gopulsa gabisa tulisanlagi ini kapan difix iya banget ini tolong, Prediksi: 0\n",
            "Text: ini iya saya top up itemku sudah benar tuh sudah terbaru aplikasinya saya bayar web habis web gak gopay nya saya manual hasilnya tidak tuh tombol transaksi ya sudah saya coba tetep gak ya sudah kayaknya gabisa deh emang bapuk ini aplikasi, Prediksi: 0\n",
            "Text: suka motong saldo diem diem aplikasi gapernah berlangganan pas cek google emang ga berlangganan tapi terpotong, Prediksi: 0\n",
            "Text: gopay buruk top up bca virtual account ga isi saldo go paynya udh hubungi cs bot solusi download lebih baik ga download ini apk ga, Prediksi: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LR TFIDF"
      ],
      "metadata": {
        "id": "QaJ7HJzSOmwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import yang diperlukan\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Ekstraksi fitur menggunakan TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=3000)  # Ambil 3000 fitur teratas\n",
        "X = tfidf.fit_transform(clean_df['clean_text']).toarray()\n",
        "y = clean_df['label']\n",
        "\n",
        "# Pembagian data 80/20 (80% untuk latih, 20% untuk uji)\n",
        "X_train_8020, X_test_8020, y_train_8020, y_test_8020 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train_8020, y_train_8020)\n",
        "\n",
        "# Prediksi dengan Logistic Regression\n",
        "y_pred_lr = lr_model.predict(X_test_8020)\n",
        "\n",
        "# Evaluasi Logistic Regression\n",
        "print(\"Logistic Regression - Classification Report:\")\n",
        "print(classification_report(y_test_8020, y_pred_lr))\n",
        "print(\"Logistic Regression - accuracy_train:\", accuracy_score(y_train_8020, lr_model.predict(X_train_8020)))\n",
        "print(\"Logistic Regression - accuracy_test:\", accuracy_score(y_test_8020, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drcKoi2uMqop",
        "outputId": "aea1c805-6954-4a8f-e2b0-33d0b2beab92"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94       612\n",
            "           1       0.00      0.00      0.00        67\n",
            "           2       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.88       695\n",
            "   macro avg       0.29      0.33      0.31       695\n",
            "weighted avg       0.78      0.88      0.82       695\n",
            "\n",
            "Logistic Regression - accuracy_train: 0.8797263233705438\n",
            "Logistic Regression - accuracy_test: 0.879136690647482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Menggunakan model untuk prediksi\n",
        "y_pred_lr = lr_model.predict(X_test_8020)  # Prediksi untuk data uji\n",
        "\n",
        "# Menampilkan hasil prediksi secara acak\n",
        "random_indices = random.sample(range(len(X_test_8020)), 10)  # Pilih 10 indeks acak\n",
        "\n",
        "print(\"Prediksi Sentimen untuk Data Uji (Acak):\")\n",
        "for i in random_indices:\n",
        "    print(f\"Text: {clean_df['clean_text'].iloc[i]}, Prediksi: {y_pred_lr[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W32xEWixNHok",
        "outputId": "4ea1d985-b9d3-48c8-e41f-ac9ddf184def"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediksi Sentimen untuk Data Uji (Acak):\n",
            "Text: aplikasi gak jelasapllikasi masalahdikit mendeteksi yang gakwajargakbisa melanjutkan pembayaranaplikasi error, Prediksi: 0\n",
            "Text: curang beli pulsa diskon rp kasih pulsa saya coba rp eh sengaja ambil kesalahan mohon perbaiki, Prediksi: 0\n",
            "Text: gopaylater ku diblokir peninjauan kunjung pulih sistem login aman setiaap login verifikasi muka keaaman khawatir dompet dicuri, Prediksi: 0\n",
            "Text: top up emoney masuk saldo gopay terpotong rp ke saldo emoney masuk top up pulsa tanggal masuk jam masuk statusnya menunggu, Prediksi: 0\n",
            "Text: aplikasi update busuk ganti devise login akun gopay disuruh verifikasi wajah gopay pakai ktp teman jakarta login akunnya tolong dihilangin fitur verifikasi muka nya ditambahi opsi off, Prediksi: 0\n",
            "Text: mengalami isi saldo gopay ngak masuk gopay bri laporan terkirim saldo kgk masuk hati penipuan, Prediksi: 0\n",
            "Text: paylater pakai kredivo shopee gopaylater terlambat sehari saja sudah langsung gak teman teman yang pakai paylater saranin pakai shopee kredivo saja terlambat dipakai namanya manusia bayar terlambat ntah lupa pas duitnya intinya dibayar gak nunggak sebulan, Prediksi: 0\n",
            "Text: sulit banget verifikasi muka permudah kenapa namanya juga muka perubahan dikit perubahan dikit ga toleransi pusing verifikasi aplikasi efektif, Prediksi: 0\n",
            "Text: membayar cicilan berulang dibuka tolong diperbaiki secepat nya jatuh tempo, Prediksi: 0\n",
            "Text: x pakai gopay pinjam x pakai paylater x terlambat bayar terlambat itupun pembayaran langsung limit gopay pinjam turun jt jt paylater belanja tokopedia blokir sudah tunggu minggu perubahan tertawa langsung uninstall, Prediksi: 0\n"
          ]
        }
      ]
    }
  ]
}