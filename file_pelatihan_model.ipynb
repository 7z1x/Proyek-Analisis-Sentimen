{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Sastrawi\n",
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD7QfLeF8na3",
        "outputId": "37d39ff4-980d-428f-cf21-94f96db2d493"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nsxOnQ8sP1_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04efb1be-d763-463c-8101-88df393d5df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah ulasan: 5000\n",
            "sentiment\n",
            "negatif    3168\n",
            "positif    1457\n",
            "netral      375\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Misalkan scrapreview sudah diubah ke DataFrame\n",
        "app_reviews_df = pd.read_csv('/content/dataset_scaraping_5000.csv')\n",
        "# Fungsi untuk memberi label berdasarkan skor\n",
        "def label_sentiment(score):\n",
        "    if score >= 4:\n",
        "        return 'positif'\n",
        "    elif score == 3:\n",
        "        return 'netral'\n",
        "    else:\n",
        "        return 'negatif'\n",
        "\n",
        "# Tambahkan kolom 'sentiment' ke DataFrame\n",
        "app_reviews_df['sentiment'] = app_reviews_df['score'].apply(label_sentiment)\n",
        "\n",
        "# Simpan ke CSV untuk memastikan hasilnya\n",
        "app_reviews_df.to_csv('ulasan_dengan_label.csv', index=False)\n",
        "\n",
        "# Cek jumlah data dan distribusi sentimen\n",
        "print(f\"Jumlah ulasan: {len(app_reviews_df)}\")\n",
        "print(app_reviews_df['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import requests\n",
        "import emoji\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Misalkan data sudah di-load dari CSV hasil langkah sebelumnya\n",
        "app_reviews_df = pd.read_csv('ulasan_dengan_label.csv')\n",
        "\n",
        "def remove_emoji(text):\n",
        "    return emoji.replace_emoji(text, replace='')\n",
        "\n",
        "def cleaningText(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # menghapus mention\n",
        "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # menghapus hashtag\n",
        "    text = re.sub(r'RT[\\s]', '', text) # menghapus RT\n",
        "    text = re.sub(r\"http\\S+\", '', text) # menghapus link\n",
        "    text = re.sub(r'[0-9]+', '', text) # menghapus angka\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) # menghapus karakter selain huruf dan angka\n",
        "    text = remove_emoji(text)  # Hapus emoji\n",
        "\n",
        "\n",
        "    text = text.replace('\\n', ' ') # mengganti baris baru dengan spasi\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # menghapus semua tanda baca\n",
        "    text = text.strip(' ') # menghapus karakter spasi dari kiri dan kanan teks\n",
        "    return text\n",
        "\n",
        "def casefoldingText(text): # Mengubah semua karakter dalam teks menjadi huruf kecil\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Fungsi stemming\n",
        "stemmer = StemmerFactory().create_stemmer()\n",
        "def stemmingText(text):\n",
        "    words = text.split()\n",
        "    return ' '.join([stemmer.stem(word) for word in words])\n",
        "\n",
        "def tokenizingText(text): # Memecah atau membagi string, teks menjadi daftar token\n",
        "    text = word_tokenize(text)\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(word_list):\n",
        "    stopwords_indonesia = stopwords.words('indonesian')\n",
        "    no_words = [w for w in word_list if w.lower() not in stopwords_indonesia]\n",
        "    return no_words\n",
        "\n",
        "def toSentence(list_words): # Mengubah daftar kata menjadi kalimat\n",
        "    sentence = ' '.join(word for word in list_words)\n",
        "    return sentence\n",
        "\n",
        "def load_slangwords():\n",
        "    slangwords = {}\n",
        "    url = 'https://raw.githubusercontent.com/louisowen6/NLP_bahasa_resources/master/combined_slang_words.txt'\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Memastikan permintaan berhasil\n",
        "        # File berformat seperti dictionary Python, jadi kita evaluasi isinya\n",
        "        slangwords = eval(response.text)  # Konversi string ke dictionary\n",
        "        return slangwords\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Gagal mengambil slangword: {e}\")\n",
        "        return {}\n",
        "\n",
        "slangwords = load_slangwords()\n",
        "\n",
        "def fix_slangwords(text):\n",
        "    words = text.split()\n",
        "    fixed_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if word.lower() in slangwords:\n",
        "            fixed_words.append(slangwords[word.lower()])\n",
        "        else:\n",
        "            fixed_words.append(word)\n",
        "\n",
        "    fixed_text = ' '.join(fixed_words)\n",
        "    return fixed_text\n",
        "\n",
        "def preprocess(text):\n",
        "    text = cleaningText(text)                # 1. Cleaning\n",
        "    text = fix_slangwords(text)              # 2. Fix slangwords\n",
        "    text = casefoldingText(text)             # 3. Case folding\n",
        "    text = stemmingText(text)                # 4. Stemming\n",
        "    tokens = tokenizingText(text)            # 5. Tokenizing\n",
        "    tokens = remove_stopwords(tokens)        # 6. Stopword Removal\n",
        "    fixed_text = ' '.join(tokens)            # 7. Gabung token jadi kalimat\n",
        "    return fixed_text\n",
        "\n",
        "\n",
        "# Terapkan preprocessing\n",
        "app_reviews_df['clean_text'] = app_reviews_df['content'].apply(preprocess)\n",
        "\n",
        "# Hapus baris dengan teks kosong\n",
        "app_reviews_df = app_reviews_df[app_reviews_df['clean_text'] != '']\n",
        "\n",
        "app_reviews_df = app_reviews_df.dropna()\n",
        "\n",
        "# Hapus duplikat\n",
        "app_reviews_df = app_reviews_df.drop_duplicates(subset=['clean_text'])\n",
        "\n",
        "# Simpan hasil\n",
        "app_reviews_df.to_csv('ulasan_clean.csv', index=False)\n",
        "\n",
        "# Cek beberapa baris\n",
        "print(app_reviews_df[['clean_text', 'sentiment']].head())\n",
        "print(f\"Jumlah data setelah preprocessing: {len(app_reviews_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYIl9IcWWTwh",
        "outputId": "47242782-8170-46d3-bb97-313b9bbe989a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          clean_text sentiment\n",
            "0  aplikasi nambah dosa sya pakai kali apk bikin ...   negatif\n",
            "3  kecewa parahhh sengaja kasih finger print upgr...   negatif\n",
            "4  aplikasi membingunkan fiturnya scrol pisah men...   negatif\n",
            "5  mohon perihal top up uang elektronik jam malam...    netral\n",
            "6  kecewa top up gak masuk masuk nunggu harikalo ...   negatif\n",
            "Jumlah data setelah preprocessing: 3468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df = pd.read_csv('ulasan_clean.csv')"
      ],
      "metadata": {
        "id": "s-O2wjLPWJeM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN-DpX6MHPLI",
        "outputId": "46666b01-7e06-4718-aaad-e03598f62df1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3468 entries, 0 to 3467\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   reviewId              3468 non-null   object\n",
            " 1   userName              3468 non-null   object\n",
            " 2   userImage             3468 non-null   object\n",
            " 3   content               3468 non-null   object\n",
            " 4   score                 3468 non-null   int64 \n",
            " 5   thumbsUpCount         3468 non-null   int64 \n",
            " 6   reviewCreatedVersion  3468 non-null   object\n",
            " 7   at                    3468 non-null   object\n",
            " 8   replyContent          3468 non-null   object\n",
            " 9   repliedAt             3468 non-null   object\n",
            " 10  appVersion            3468 non-null   object\n",
            " 11  sentiment             3468 non-null   object\n",
            " 12  clean_text            3468 non-null   object\n",
            "dtypes: int64(2), object(11)\n",
            "memory usage: 352.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM TF-IDF"
      ],
      "metadata": {
        "id": "4Lalo5yWHgLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load data yang sudah dibersihkan\n",
        "clean_df = pd.read_csv('ulasan_clean.csv')\n",
        "\n",
        "# Mapping label ke angka\n",
        "label_map = {'negatif': 0, 'netral': 1, 'positif': 2}\n",
        "clean_df['label'] = clean_df['sentiment'].map(label_map)\n",
        "\n",
        "# Ekstraksi fitur TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=3468)  # ambil fitur top\n",
        "X = tfidf.fit_transform(clean_df['clean_text']).toarray()\n",
        "y = clean_df['label']\n",
        "\n",
        "# Split data 80% train / 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Training SVM\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred_train_svm = svm_model.predict(X_train)\n",
        "y_pred_test_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluasi akurasi\n",
        "accuracy_train_svm = accuracy_score(y_train, y_pred_train_svm)\n",
        "accuracy_test_svm = accuracy_score(y_test, y_pred_test_svm)\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(\"SVM - Accuracy Train:\", accuracy_train_svm)\n",
        "print(\"SVM - Accuracy Test:\", accuracy_test_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUAsZjlnYfrh",
        "outputId": "7c9dc952-2c76-4643-e27b-4518b16702fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM - Accuracy Train: 0.8767123287671232\n",
            "SVM - Accuracy Test: 0.8746397694524496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Menggunakan model untuk prediksi\n",
        "y_pred_test_svm = svm_model.predict(X_test)  # Prediksi untuk data uji\n",
        "\n",
        "# Menampilkan hasil prediksi secara acak\n",
        "random_indices = random.sample(range(len(X_test)), 10)  # Pilih 10 indeks acak\n",
        "\n",
        "print(\"Prediksi Sentimen untuk Data Uji (Acak):\")\n",
        "for i in random_indices:\n",
        "    print(f\"Text: {clean_df['clean_text'].iloc[i]}, Prediksi: {y_pred_test_svm[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwEapa6iYhpH",
        "outputId": "fad04553-4f8e-4d3a-a6a1-710a534b2828"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediksi Sentimen untuk Data Uji (Acak):\n",
            "Text: kecewa layan ikan gopay tranfer bank proses saldo kosong tunggu terang proses lapor cs alas suruh nunggu kerja kecewa aplikasi, Prediksi: 0\n",
            "Text: tolong tunggu aktivasi kasih tulis menit ditungguin jam kabar tolong tulis gak biar gak nunggu loh tulis, Prediksi: 0\n",
            "Text: pakai gopay udh bertaunbaru kecewa kali upgrade gopay tabung top up saldo masuk uang hilang masuk bantu ga upload foto buktiauto pindah belah mah, Prediksi: 0\n",
            "Text: kondisi urgent error gak transfer nerima transfer cepat banget apk aneh parah, Prediksi: 0\n",
            "Text: tampil ampas banget bingungin tolong gausah designnya fungsional, Prediksi: 0\n",
            "Text: gopay parah ga rekomended akses susah bayar tagih susah saldo situ kemarin komplin susah akses nyata tetep solusi testimoni negatif gitu masak ga on the way jalan uninstall nihsalam, Prediksi: 0\n",
            "Text: aplikasi parahh seduniaudah verfikasi wajah pencahyaan tetep gagalmana uang aplikasi butuh bangetkirim bantu gak solusiparahhh, Prediksi: 0\n",
            "Text: customer servicenya gk pakai voucher cashback gk cashback sesuai sk laku lapor banding tolak sial, Prediksi: 0\n",
            "Text: aplikasi kocak banget deh masuk x doang akun coba tugas tuh developer kerjain bnr masuk x doang slalu tunda menit aplikasi make sistem nya, Prediksi: 0\n",
            "Text: henti aplikasi langgan biar saldo potong otomatis menu aplikasi aplikasi henti langgan parah aplikasi mu main potong saldo henti langgan menu, Prediksi: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RF-WordVec"
      ],
      "metadata": {
        "id": "JaxOvVWmTFVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load data bersih\n",
        "data = pd.read_csv('ulasan_clean.csv')\n",
        "label_map = {'negatif': 0, 'netral': 1, 'positif': 2}\n",
        "data['label'] = data['sentiment'].map(label_map)\n",
        "\n",
        "# Tokenizing untuk Word2Vec\n",
        "data['tokens'] = data['clean_text'].apply(nltk.word_tokenize)\n",
        "\n",
        "# Train Word2Vec model\n",
        "w2v_model = Word2Vec(sentences=data['tokens'], vector_size=100, window=5, min_count=1, sg=1)\n",
        "\n",
        "# Fungsi untuk merata-rata embedding setiap kalimat\n",
        "def vector_average(tokens):\n",
        "    vectors = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(w2v_model.vector_size)\n",
        "\n",
        "# Konversi semua text jadi vektor\n",
        "X_vectors = np.array([vector_average(tokens) for tokens in data['tokens']])\n",
        "y = data['label']\n",
        "\n",
        "# Split data\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(\n",
        "    X_vectors, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Training Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_w2v, y_train_w2v)\n",
        "\n",
        "y_pred_train_rf = rf_model.predict(X_train_w2v)\n",
        "y_pred_test_rf = rf_model.predict(X_test_w2v)\n",
        "\n",
        "print(\"Random Forest - accuracy_train:\", accuracy_score(y_pred_train_rf, y_train_w2v))\n",
        "print(\"Random Forest - accuracy_test :\", accuracy_score(y_pred_test_rf, y_test_w2v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYo6mcIzYlrd",
        "outputId": "78ab84b2-e788-4214-acc8-a41dfb5f4715"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - accuracy_train: 1.0\n",
            "Random Forest - accuracy_test : 0.8746397694524496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_df['sentiment'].value_counts())\n",
        "print(f\"Training data: {len(X_train_w2v)}\")\n",
        "print(f\"Testing data: {len(X_test_w2v)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyHu7L_0YoJF",
        "outputId": "5f3c2f83-d7f3-472d-f203-8e7811ddbc5e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "negatif    3033\n",
            "netral      357\n",
            "positif      78\n",
            "Name: count, dtype: int64\n",
            "Training data: 2774\n",
            "Testing data: 694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train_w2v, y_pred_train_rf)\n",
        "\n",
        "print(f\"Data training balanced: {Counter(y_train_bal)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKeq64xlYpUw",
        "outputId": "c5daed67-5c27-46f9-e8ec-7e6cd5b1cd0a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x79a0d565aac0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
            "    self._make_controller_from_path(filepath)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1187, in _make_controller_from_path\n",
            "    lib_controller = controller_class(\n",
            "                     ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 114, in __init__\n",
            "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "OSError: dlopen() error\n",
            "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x79a0d565aac0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
            "    self._make_controller_from_path(filepath)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1187, in _make_controller_from_path\n",
            "    lib_controller = controller_class(\n",
            "                     ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 114, in __init__\n",
            "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "OSError: dlopen() error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data training balanced: Counter({0: 2426, 1: 2426, 2: 2426})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model Random Forest dengan data yang seimbang\n",
        "rf_model_bal = RandomForestClassifier(random_state=42)\n",
        "rf_model_bal.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "# Prediksi pada data uji\n",
        "y_pred_bal = rf_model_bal.predict(X_test_w2v)\n",
        "\n",
        "# Evaluasi Model\n",
        "print(\"Random Forest (Data Seimbang) - Classification Report:\")\n",
        "print(classification_report(y_pred_test_rf, y_pred_bal))\n",
        "print(\"Akurasi (Test Data):\", accuracy_score(y_pred_test_rf, y_pred_bal))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQX71bANYqjJ",
        "outputId": "dba60ef5-c34e-4977-d911-369be893c393"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest (Data Seimbang) - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96       692\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.07      1.00      0.12         1\n",
            "\n",
            "    accuracy                           0.92       694\n",
            "   macro avg       0.36      0.64      0.36       694\n",
            "weighted avg       1.00      0.92      0.95       694\n",
            "\n",
            "Akurasi (Test Data): 0.9164265129682997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan model untuk prediksi\n",
        "y_pred_bal = rf_model_bal.predict(X_test_w2v)  # Prediksi untuk data uji\n",
        "\n",
        "# Menampilkan hasil prediksi secara acak\n",
        "random_indices = random.sample(range(len(X_test_w2v)), 10)  # Pilih 10 indeks acak\n",
        "\n",
        "print(\"Prediksi Sentimen untuk Data Uji (Acak):\")\n",
        "for i in random_indices:\n",
        "    print(f\"Text: {clean_df['clean_text'].iloc[i]}, Prediksi: {y_pred_bal[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBFN9z8bYr4H",
        "outputId": "56fe238c-b4dc-4b27-ce90-1a29aafa78b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediksi Sentimen untuk Data Uji (Acak):\n",
            "Text: kecewa aplikasi pakai aplikasi transfer status memprosesdi suruh hubung cs jawabanudh proses gak uang nya pakai ngopi kali iya, Prediksi: 0\n",
            "Text: ken beli makan pakai qris sulit gmn uang tahan gopay transfer notif transaksi curiga transaksi bayar makan tolong uang gk pakai, Prediksi: 0\n",
            "Text: aplikasi buruk sekalibanyak no wa masuk ancamanan sebar data sesuai iklan, Prediksi: 0\n",
            "Text: top up gopay ga masuk kadang masuk lambat jm masuk kecewa banget skarang top up saldo masuk skali, Prediksi: 0\n",
            "Text: download pakai aplikasi gopay iniuntuk alam kali uang tf hilang bank terima masukmau hubung gopay susah alam buruk apk gopaymending pakai apk dana sajalancar apk dana ukses, Prediksi: 0\n",
            "Text: x transaksi top up game berturutturut voucher cashback pakai payment ga masuk cashback nya lumayan top up gopay gada kendala lapor responnya g niat bikin promo ga ush nawarin spam notifikasi bikin tarik bodoh males pakai gopay pindah aplikasi belah, Prediksi: 0\n",
            "Text: parah gopay kecewa mah top up tanggal maret saldo ga masuk transfer ribet pakai acara metode bayar segalabener ga pindah aplikasi, Prediksi: 0\n",
            "Text: upgrade gopay plus tulis dokumen upload truss jam notif, Prediksi: 0\n",
            "Text: promo sms token listrik rp bayar ribu instal promo murah tarik top up beli promo ubah bayar lanjur top up paksa beli sesuai promonya tipu gin sih, Prediksi: 0\n",
            "Text: parahhhh aplikasi niiii transfer ga upgrade gilir upgrade foto ga pas ktp susah aplikasi bantu ga becus lapor ga pokok uang sangkut situ ga transfer, Prediksi: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LR TF-IDF"
      ],
      "metadata": {
        "id": "GZHrGAXLTQN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# Ekstraksi fitur menggunakan TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=3468)  # Ambil 3000 fitur teratas\n",
        "X = tfidf.fit_transform(clean_df['clean_text']).toarray()\n",
        "y = clean_df['label']\n",
        "\n",
        "# Pembagian data 80/20 (80% untuk latih, 20% untuk uji)\n",
        "X_train_8020, X_test_8020, y_train_8020, y_test_8020 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train_8020, y_train_8020)\n",
        "\n",
        "# Prediksi dengan Logistic Regression\n",
        "y_pred_lr = lr_model.predict(X_test_8020)\n",
        "\n",
        "# Evaluasi Logistic Regression\n",
        "print(\"Logistic Regression - Classification Report:\")\n",
        "print(classification_report(y_test_8020, y_pred_lr))\n",
        "print(\"Logistic Regression - accuracy_train:\", accuracy_score(y_train_8020, lr_model.predict(X_train_8020)))\n",
        "print(\"Logistic Regression - accuracy_test:\", accuracy_score(y_test_8020, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ6OalmeYsqT",
        "outputId": "d87723de-eda7-4744-b6f4-735a32c6f4d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       604\n",
            "           1       0.00      0.00      0.00        76\n",
            "           2       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.87       694\n",
            "   macro avg       0.29      0.33      0.31       694\n",
            "weighted avg       0.76      0.87      0.81       694\n",
            "\n",
            "Logistic Regression - accuracy_train: 0.8795962509012256\n",
            "Logistic Regression - accuracy_test: 0.8688760806916427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Menggunakan model untuk prediksi\n",
        "y_pred_lr = lr_model.predict(X_test_8020)  # Prediksi untuk data uji\n",
        "\n",
        "# Menampilkan hasil prediksi secara acak\n",
        "random_indices = random.sample(range(len(X_test_8020)), 10)  # Pilih 10 indeks acak\n",
        "\n",
        "print(\"Prediksi Sentimen untuk Data Uji (Acak):\")\n",
        "for i in random_indices:\n",
        "    print(f\"Text: {clean_df['clean_text'].iloc[i]}, Prediksi: {y_pred_lr[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr7KDaHXYuR9",
        "outputId": "b0aba4f2-3d62-4694-88ab-ad28ba952402"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediksi Sentimen untuk Data Uji (Acak):\n",
            "Text: gopay sih suami salah nomer nomer aktif nomernya daftar gopay aneh nya transfer hasil duit lenyap bgtu, Prediksi: 0\n",
            "Text: kesan maksa banget marketing ajarin banyakin doang kesan nyaman utamain gerak bidang uang elektronik tuju transaksi uang bayar transfer bayar paksa upgrade buang busukk, Prediksi: 0\n",
            "Text: kecewa aplikasi pakai aplikasi transfer status memprosesdi suruh hubung cs jawabanudh proses gak uang nya pakai ngopi kali iya, Prediksi: 0\n",
            "Text: bintang laku beli google play kali game mobile legends cashback parah go pay tulis cashback sd rp minimal beli rp cashback nya beli wdp loh harga rp, Prediksi: 0\n",
            "Text: mudah kecoh tawar promo sistem kerja tipu promo hasil promo mengajulan banding hasil ikan aplikasi bagus pilih metode payment kecewa, Prediksi: 0\n",
            "Text: kecewa top up masuk pemberitahuan data transaksi masuk saldo masuk butuh bantu live chat susah banget lambat idulfitri taruh halaman biar costumer taro halaman bantu cari susah, Prediksi: 0\n",
            "Text: aplikasi gak anjing top up kali nya selesai gopay nya gak masuk anjing jam gak masuk stres aplikasi aneh parah gak ngaco gak tuh duit nya parah penasaran nyoba isi takut gak masuk parah tipu, Prediksi: 0\n",
            "Text: lucu lucu bayar drama notif aktivitas wajar bayar pakai saldo hasil duit halal akun gak dipake nuyul promo pas bayar terang gitu konsultasi cs kocak emang belah gak drama drama indosiar kocak kocak, Prediksi: 0\n",
            "Text: top up juta minggu saldo ga masuk respon cs template banget ga saldo komplain aplikasi tutup ga komen aneh rugi konsumen banget, Prediksi: 1\n",
            "Text: sumpah paket mb beli paket data gopay tibatiba saldo gak sulit banget beli paket data doang kaya dana shopeepay paket data sisah mb beli paket data berat aplikasi broo laen kali kasih rincian gbnya internet sosmednya rinci berat banget apk rinci banget pulak, Prediksi: 0\n"
          ]
        }
      ]
    }
  ]
}